{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Prediction using PPG signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the parent directory (i.e. transformer, means parent directory of 'scripts' and 'notebooks') to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import the function\n",
    "from scripts.basic_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loader\n",
    "def data_loader(subject, action):\n",
    "    '''\n",
    "    Automate input reading: select subject, action\n",
    "    Read in csv file\n",
    "    '''\n",
    "    df_data_ppg = pd.read_csv(\n",
    "        '../data/Finger/csv/s'+ str(subject) + '_' + str(action) + '.csv',\n",
    "        sep=',',           # specify delimiter (default is ',')\n",
    "        header=0,          # row number to use as column names (0 means the first row)\n",
    "        na_values=['NA', ''],  # specify which values should be considered NaN\n",
    "    )\n",
    "    return df_data_ppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data and sampling frequency\n",
    "fs = 500  \n",
    "\n",
    "# Define bandpass range for PPG \n",
    "lowcut = 0.4\n",
    "highcut = 10\n",
    "\n",
    "df_data = data_loader(subject=10, action='sit')\n",
    "df_ecg = df_data.iloc[:,[1]]\n",
    "df_ecg['ecg'] = bandpass_filter(df_ecg['ecg'], lowcut, highcut, fs, order=4)\n",
    "print(df_ecg)\n",
    "df_ppg = df_data.iloc[:,[6,7,8]]\n",
    "print(df_ppg)\n",
    "df_ppg['pleth_4'] = bandpass_filter(df_data['pleth_4'], lowcut, highcut, fs, order=4)\n",
    "df_ppg['pleth_5'] = bandpass_filter(df_data['pleth_5'], lowcut, highcut, fs, order=4)\n",
    "df_ppg['pleth_6'] = bandpass_filter(df_data['pleth_6'], lowcut, highcut, fs, order=4)\n",
    "df_ppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_tensor = torch.tensor(df_ecg['ecg'].values).float().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize ppg signals\n",
    "scaler = MinMaxScaler()\n",
    "ppg_normalized = scaler.fit_transform(df_ppg)\n",
    "ppg_tensor = torch.tensor(ppg_normalized, dtype=torch.float32)\n",
    "ppg_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and slice ecg_tensor\n",
    "subset = 1099\n",
    "target_sequence = ecg_tensor[:subset-99]\n",
    "\n",
    "def create_sequences(ppg_data, ecg_data, sequence_length):\n",
    "    sequences_ppg = []\n",
    "    sequences_ecg = []\n",
    "    for i in range(len(ppg_data) - sequence_length + 1):\n",
    "        seq_ppg = ppg_data[i:i + sequence_length]\n",
    "        seq_ecg = ecg_data[i:i + sequence_length]\n",
    "        sequences_ppg.append(seq_ppg)\n",
    "        sequences_ecg.append(seq_ecg)\n",
    "    return torch.stack(sequences_ppg), torch.stack(sequences_ecg)\n",
    "\n",
    "sequence_length = 100  # Example: sequences_ppg of 100 timesteps\n",
    "input_sequences, target_sequence = create_sequences(ppg_tensor[:subset], ecg_tensor[:subset], sequence_length)\n",
    "\n",
    "print(input_sequences.size())\n",
    "print(target_sequence.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = input_sequences  # Shape (1000, 100, 3) (PPG data)\n",
    "y_data = target_sequence  # Shape (1000, 1) (ECG data)\n",
    "\n",
    "# Check if the shape of both is aligned\n",
    "assert x_data.shape[0] == y_data.shape[0], \"Number of samples do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len = 100):\n",
    "        super().__init__()  # new version of: super(PositionalEncodingLayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        print(\"Shape of pe:\", pe.size())\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # Shape: [max_len, 1], Arange: Returns a 1-D tensor from start to stop, Unsqueeze: Returns a new tensor with a dimension of size one inserted at the specified position\n",
    "        print(\"Shape of position:\", position.size())\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)) # Shape: [d_model // 2]\n",
    "        print(\"Shape of div_term\", div_term.size())\n",
    "        \n",
    "        # Expand div_term to match the shape of position\n",
    "        div_term = div_term.unsqueeze(0)  # Shape: [1, d_model // 2]\n",
    "        div_term = div_term.expand(max_len, -1)  # Shape: [max_len, d_model // 2]\n",
    "\n",
    "        # Make sure div_term is of shape [max_len, d_model] to broadcast properly\n",
    "        div_term_full = torch.zeros(max_len, d_model)\n",
    "        div_term_full[:, 0::2] = div_term  # Fill every other column with div_term\n",
    "        print(\"Corrected shape of div_term\", div_term.size())\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term_full[:, 0::2])  # Sine for even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term_full[:, 1::2])  # Cosine for odd indices\n",
    "        # pe = pe.unsqueeze(0)\n",
    "        # x = x + pe[:, :x.size(1)]\n",
    "        \n",
    "        self.pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to input tensor\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = input_sequences.shape[2]  # Number of features\n",
    "positional_encoding = PositionalEncoding(d_model)\n",
    "pe_input_seq = positional_encoding(input_sequences)\n",
    "print(\"Output shape:\", pe_input_seq.size())\n",
    "print(\"sample of pe:\", pe_input_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTimeSeries(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_layers=4, d_model=32, nhead=4, dim_feedforward=128, dropout=0.1):\n",
    "        super(TransformerTimeSeries, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * torch.sqrt(torch.tensor(src.size(-1), dtype=torch.float32))\n",
    "        src = self.positional_encoding(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.fc_out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ratio \n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * x_data.size(0))  # Number of training samples\n",
    "val_size = x_data.size(0) - train_size          # Number of validation samples\n",
    "\n",
    "# Option 1: Manual slicing (if shuffle is not needed)\n",
    "X_train, X_val = x_data[:train_size], x_data[train_size:]\n",
    "y_train, y_val = y_data[:train_size], y_data[train_size:]\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"x_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization \n",
    "d_model = 32  # Embedding dimension\n",
    "input_dim = 3  # 3 PPG signals (red, green, IR)\n",
    "output_dim = 1  # 1 ECG target per time step\n",
    "nhead = 8  # Attention heads\n",
    "num_layers = 4  # Number of transformer layers\n",
    "batch_size = 32  # Batch size\n",
    "\n",
    "\n",
    "model = TransformerTimeSeries(input_dim=input_dim, output_dim=output_dim, d_model=d_model, nhead=nhead, num_layers=num_layers) # Replace 1 with your output features\n",
    "output = model(pe_input_seq)\n",
    "\n",
    "# Loss function: Mean Squared Error for regression tasks\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer: Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10  # Number of epochs to train\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    # Initialize running loss\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate through the training data in batches\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        # Get the current batch\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        predictions = model(batch_X)\n",
    "\n",
    "        # Calculate loss (MSE between predicted ECG and actual ECG)\n",
    "        loss = loss_fn(predictions, batch_y)\n",
    "\n",
    "        # Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate the average loss for the epoch\n",
    "    avg_loss = running_loss / len(X_train)\n",
    "    \n",
    "    # Validation metrics (optional but useful)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_val)\n",
    "        val_loss = loss_fn(val_predictions, y_val).item()\n",
    "        val_rmse = torch.sqrt(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f} | Val RMSE: {val_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After calculating val_loss (MSE loss on validation data):\n",
    "val_rmse = torch.sqrt(val_loss)  # RMSE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
